{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextMining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "# 트레이닝 데이터로 할당하기\n",
    "x = np.array([[-3,7], [1,5], [1,2], [-2,0], [2,3], [-4,0], [-1,1], [1,1], [-2,2], [2,7], [-4,1], [-2,7]])\n",
    "\n",
    "# 클래스 라벨을 3과 4로 붙여주기\n",
    "y = np.array([3,3,3,3,4,3,3,4,3,4,4,4])\n",
    "\n",
    "# 나이브 베이지안 분류기를 만들기.\n",
    "model = GaussianNB()\n",
    "\n",
    "# 모델을 학습시키기\n",
    "model.fit(x,y)\n",
    "\n",
    "# 아웃풋을 예측하기\n",
    "predicted = model.predict([[1,0], [-4,0], [-8,-16]])\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = [0,2,1,3]\n",
    "y_true = [0,1,2,3]\n",
    "\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "무비 리뷰 자동 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 베르누이 나이브 베이즈 \n",
    ">그것은 우리의 모든 기능들은 두 개의 값을 가질 수 있도록 바이너리 있다고 가정합니다. 의미 0 은 \"문서에서 단어가 발생하지 않음\"을 나타내고 1 은 \"문서에서 단어가 발생 함\"을 나타냅니다.\n",
    "\n",
    "2. Multinomial Naive Bayes \n",
    ">이산 베이지 (Naive Bayes) : 이산 데이터 가있을 때 사용됩니다 (예 : 각 등급이 나타내는 특정 빈도 로 1 ~ 5 등급의 영화 등급 ). 텍스트 학습에서 우리는 클래스 또는 라벨을 예측할 각 단어의 수를가집니다.\n",
    "\n",
    "3. Gaussian Naive Bayes\n",
    ">정규 분포를 가정하기 때문에 모든 특징이 연속적 일 때 Gaussian Naive Bayes가 사용됩니다 . 예를 들어 아이리스 데이터 세트의 특징은 세팔 너비, 꽃잎 너비, 세팔 길이, 꽃잎 길이입니다. 따라서 폭과 길이가 다를 수 있기 때문에 데이터의 특성이 서로 다른 값을 가질 수 있습니다. 우리는 사건과 관련된 특징을 표현할 수 없다. 이것은 데이터가 연속적임을 의미합니다. 그러므로 우리는 여기서 Gaussian Naive Bayes를 사용합니다.\n",
    "\n",
    "출처: https://www.quora.com/What-is-the-difference-between-the-the-Gaussian-Bernoulli-Multinomial-and-the-regular-Naive-Bayes-algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 =  0.81432\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "\n",
    "reviews_train = load_files(\"./aclImdb/train\")\n",
    "reviews_test = load_files(\"./aclImdb/test\")\n",
    "\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "\n",
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]\n",
    "text_test = [doc.replace(b\"<br />\", b\" \") for doc in text_test]\n",
    "\n",
    "# 영화 리뷰 학습 데이터와 테스트 데이터에 대한 BOW 생성\n",
    "# 주의: 테스트 데이터에 대한 BOW 생성 시, 학습 데이터에서 생성한 어휘사전 사용\n",
    "vect = CountVectorizer().fit(text_train)\n",
    "x_train = vect.transform(text_train)\n",
    "x_test = vect.transform(text_test)\n",
    "\n",
    "#가우시안 나이브베이즈는 희소행렬을 입력으로 받지 못함\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train, y_train)\n",
    "pre = nb.predict(x_test)\n",
    "\n",
    "ac_score = metrics.accuracy_score(y_test, pre)\n",
    "print(\"정답률 = \",ac_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "멀티노미알 분포 스무딩 (알파값의 튜닝)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 =  0.80676\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "\n",
    "reviews_train = load_files(\"./aclImdb/train\")\n",
    "reviews_test = load_files(\"./aclImdb/test\")\n",
    "\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "\n",
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]\n",
    "text_test = [doc.replace(b\"<br />\", b\" \") for doc in text_test]\n",
    "\n",
    "# 영화 리뷰 학습 데이터와 테스트 데이터에 대한 BOW 생성\n",
    "# 주의: 테스트 데이터에 대한 BOW 생성 시, 학습 데이터에서 생성한 어휘사전 사용\n",
    "vect = CountVectorizer().fit(text_train)\n",
    "x_train = vect.transform(text_train)\n",
    "x_test = vect.transform(text_test)\n",
    "\n",
    "#가우시안 나이브베이즈는 희소행렬을 입력으로 받지 못함\n",
    "nb = MultinomialNB(alpha=0.2) #디폴트 값은 1\n",
    "nb.fit(x_train, y_train)\n",
    "pre = nb.predict(x_test)\n",
    "\n",
    "ac_score = metrics.accuracy_score(y_test, pre)\n",
    "print(\"정답률 = \",ac_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또 다른 알파 값 줘 보기 (0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 =  0.81188\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "\n",
    "reviews_train = load_files(\"./aclImdb/train\")\n",
    "reviews_test = load_files(\"./aclImdb/test\")\n",
    "\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "\n",
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]\n",
    "text_test = [doc.replace(b\"<br />\", b\" \") for doc in text_test]\n",
    "\n",
    "# 영화 리뷰 학습 데이터와 테스트 데이터에 대한 BOW 생성\n",
    "# 주의: 테스트 데이터에 대한 BOW 생성 시, 학습 데이터에서 생성한 어휘사전 사용\n",
    "vect = CountVectorizer().fit(text_train)\n",
    "x_train = vect.transform(text_train)\n",
    "x_test = vect.transform(text_test)\n",
    "\n",
    "#가우시안 나이브베이즈는 희소행렬을 입력으로 받지 못함\n",
    "nb = MultinomialNB(alpha=0.7) #디폴트 값은 1\n",
    "nb.fit(x_train, y_train)\n",
    "pre = nb.predict(x_test)\n",
    "\n",
    "ac_score = metrics.accuracy_score(y_test, pre)\n",
    "print(\"정답률 = \",ac_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또 다른 알파값 줘보기 (1.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 =  0.8164\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "\n",
    "reviews_train = load_files(\"./aclImdb/train\")\n",
    "reviews_test = load_files(\"./aclImdb/test\")\n",
    "\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "\n",
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]\n",
    "text_test = [doc.replace(b\"<br />\", b\" \") for doc in text_test]\n",
    "\n",
    "# 영화 리뷰 학습 데이터와 테스트 데이터에 대한 BOW 생성\n",
    "# 주의: 테스트 데이터에 대한 BOW 생성 시, 학습 데이터에서 생성한 어휘사전 사용\n",
    "vect = CountVectorizer().fit(text_train)\n",
    "x_train = vect.transform(text_train)\n",
    "x_test = vect.transform(text_test)\n",
    "\n",
    "#가우시안 나이브베이즈는 희소행렬을 입력으로 받지 못함\n",
    "nb = MultinomialNB(alpha=1.8) #디폴트 값은 1\n",
    "nb.fit(x_train, y_train)\n",
    "pre = nb.predict(x_test)\n",
    "\n",
    "ac_score = metrics.accuracy_score(y_test, pre)\n",
    "print(\"정답률 = \",ac_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF 사용 자동 분류, TfidfVectorizor 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 =  0.83024\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "\n",
    "reviews_train = load_files(\"./aclImdb/train\")\n",
    "reviews_test = load_files(\"./aclImdb/test\")\n",
    "\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "\n",
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]\n",
    "text_test = [doc.replace(b\"<br />\", b\" \") for doc in text_test]\n",
    " \n",
    "# tf-idf 벡터 사용\n",
    "vect = TfidfVectorizer().fit(text_train)\n",
    "x_train = vect.transform(text_train)\n",
    "x_test = vect.transform(text_test)\n",
    "\n",
    "nb = MultinomialNB()  \n",
    "nb.fit(x_train, y_train)\n",
    "pre = nb.predict(x_test)\n",
    "\n",
    "ac_score = metrics.accuracy_score(y_test, pre)\n",
    "print(\"정답률 = \",ac_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "알파 값 튜닝해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 =  0.83172\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "\n",
    "reviews_train = load_files(\"./aclImdb/train\")\n",
    "reviews_test = load_files(\"./aclImdb/test\")\n",
    "\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "\n",
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]\n",
    "text_test = [doc.replace(b\"<br />\", b\" \") for doc in text_test]\n",
    " \n",
    "# tf-idf 벡터 사용\n",
    "vect = TfidfVectorizer().fit(text_train)\n",
    "x_train = vect.transform(text_train)\n",
    "x_test = vect.transform(text_test)\n",
    "\n",
    "#가우시안 나이브베이즈는 희소행렬을 입력으로 받지 못함\n",
    "nb = MultinomialNB(alpha=1.8)  \n",
    "nb.fit(x_train, y_train)\n",
    "pre = nb.predict(x_test)\n",
    "\n",
    "ac_score = metrics.accuracy_score(y_test, pre)\n",
    "print(\"정답률 = \",ac_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
